{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.7.4 (default, Oct  4 2019, 06:57:26) \\n[GCC 9.2.0]'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"tests/test_data\"\n",
    "HOW_MUCH = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate clean recordings\n",
    "\n",
    "### define mapping to STFT\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def mapping(wave):\n",
    "    wave = wave.astype(np.float32) / 2**15\n",
    "    length = (len(wave) - 512) // 256  # shortcut here\n",
    "    spec = np.zeros([length, 257], np.complex64)\n",
    "    for i in range(length):\n",
    "        spec[i, :] = np.fft.rfft(wave[i * 256 : i * 256 + 512])\n",
    "    return spec\n",
    "\n",
    "### list recordings\n",
    "import os\n",
    "\n",
    "records = [x for x in os.listdir(PATH) if x.endswith(\".wav\")]\n",
    "records = [os.path.join(PATH, x) for x in records]\n",
    "\n",
    "### load cleans\n",
    "import scipy.io.wavfile as sio\n",
    "\n",
    "clean_lengths = [sio.read(x)[1].shape for x in records]\n",
    "cleans = [mapping(sio.read(x)[1]) for x in records]\n",
    "spec_lens = [x.shape[0] for x in cleans]\n",
    "max_spec_len = max([x.shape[0] for x in cleans])\n",
    "cleans = np.stack([np.pad(x, ((max_spec_len - x.shape[0], 0), (0, 0)), 'constant') for x in cleans])\n",
    "\n",
    "### mix them up - two mixtures\n",
    "components_1 = np.stack([cleans[np.random.randint(cleans.shape[0])] for x in range(HOW_MUCH)])\n",
    "components_2 = np.stack([cleans[np.random.randint(cleans.shape[0])] for x in range(HOW_MUCH)])\n",
    "mixtures = np.stack([(components_1[x] + components_2[x]) for x in range(HOW_MUCH)])\n",
    "\n",
    "### map them\n",
    "components_1 = np.abs(components_1)\n",
    "components_2 = np.abs(components_2)\n",
    "mixtures = np.abs(mixtures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# build model\n",
    "\n",
    "from keras import layers, models\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "first = layers.Input(shape=(None, 257))\n",
    "lyr = first\n",
    "lyr = layers.Dense(512, activation='sigmoid')(lyr)\n",
    "lyr = layers.Convolution1D(kernel_size=5, filters=512, activation='relu', padding='same')(lyr)\n",
    "lyr = layers.Convolution1D(kernel_size=5, filters=512, activation='relu', padding='same')(lyr)\n",
    "lyr = layers.LSTM(512, return_sequences=True)(lyr)\n",
    "lyr = layers.LSTM(512, return_sequences=True, activation='sigmoid')(lyr)\n",
    "lyr = layers.Lambda(lambda x: K.stack([x[:, :, :256], x[:, :, 256:]], axis=-1))(lyr)\n",
    "lyr = layers.Lambda(lambda x: tf.pad(x, ((0, 0), (0, 0), (1, 0), (0, 0))))(lyr)\n",
    "lyr = layers.Lambda(lambda x: x[0] * K.stack([x[1], x[1]], axis=-1) )([lyr, first])\n",
    "mdl = models.Model(first, lyr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, 257)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 512)    132096      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, None, 512)    1311232     dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, None, 512)    1311232     conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, None, 512)    2099200     conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, None, 512)    2099200     lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, None, 256, 2) 0           lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, None, 257, 2) 0           lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, None, 257, 2) 0           lambda_2[0][0]                   \n",
      "                                                                 input_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 6,952,960\n",
      "Trainable params: 6,952,960\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mdl.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define PIT loss\n",
    "\n",
    "def pit_loss(true, targets):\n",
    "    return K.min([\n",
    "        K.mean(K.mean(((true[:, :, :, 0] - targets[:, :, :, 0]) ** 2 + (true[:, :, :, 1] - targets[:, :, :, 1]) ** 2))),\n",
    "        K.mean(K.mean(((true[:, :, :, 0] - targets[:, :, :, 1]) ** 2 + (true[:, :, :, 1] - targets[:, :, :, 0]) ** 2)))\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl.compile('adam', pit_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "10/10 [==============================] - 43s 4s/step - loss: 7278.7518\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f91907e2050>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl.fit(mixtures, np.stack([components_1, components_2], axis=-1), epochs=1, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
